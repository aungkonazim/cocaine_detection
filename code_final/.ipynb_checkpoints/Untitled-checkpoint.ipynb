{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "x = loadmat('theta.mat')\n",
    "theta_array = x['theta_array'][0]\n",
    "theta_label = x['theta_label'][0]\n",
    "X_digits = np.reshape(theta_array[0:1108],[1108,1])\n",
    "y_digits = theta_label\n",
    "\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "X_train = X_digits\n",
    "y_train = y_digits\n",
    "X_test = X_digits\n",
    "y_test = y_digits\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f' % logistic.fit(X_train, y_train).score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "x = loadmat('theta.mat')\n",
    "theta_array = x['theta_array'][0]\n",
    "theta_label = x['theta_label'][0]\n",
    "X_digits = np.reshape(theta_array[0:1108],[1108,1])\n",
    "y_digits = theta_label\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(knn, X_digits, y_digits, cv=3)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "x = loadmat('theta1.mat')\n",
    "\n",
    "\n",
    "f1 = x['theta_array'][0]\n",
    "f2 = x['duration_array'][0]\n",
    "X_digits = [[f1[i],f2[i]] for i in range(len(f1))]\n",
    "y_digits = x['theta_label'][0]\n",
    "clf = svm.SVC('kernel': 'rbf', 'C': 0.000244140625, 'gamma': 0.000244140625, 'class_weight': {0: 0.5, 1: 0.5})\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "clf.fit(X_digits,y_digits)\n",
    "print(sum(y_digits))\n",
    "print(sum(clf.predict(X_digits)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "x = loadmat('theta3_activation_0_1.mat')\n",
    "\n",
    "\n",
    "f1 = x['theta_array'][0]\n",
    "f2 = x['duration_array'][0]\n",
    "f3 = x['subject_array'][0]\n",
    "\n",
    "traindata = [[f1[i],f2[i]] for i in range(len(f1))]\n",
    "trainlabels = x['theta_label'][0]\n",
    "lkf = LabelKFold(f3, n_folds=len(np.unique(f3)))\n",
    "\n",
    "delta = 0.5\n",
    "parameters = {'kernel': ['rbf','linear'],\n",
    "              'C': [2 ** x for x in np.arange(-12, 12, .5)],\n",
    "              'gamma': [2 ** x for x in np.arange(-12, 12, .5)],\n",
    "              'class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.0, 1.0, delta)]}\n",
    "\n",
    "svc = svm.SVC(probability=True, verbose=False, cache_size=200)\n",
    "clf = GridSearchCV(estimator=svc, param_grid=parameters,cv=lkf, n_jobs=2, scoring='f1_weighted', verbose=1, iid=False)\n",
    "clf.fit(traindata,trainlabels)\n",
    "print(clf.best_params_)\n",
    "# print(sum(clf.predict(traindata)))\n",
    "\n",
    "recall= recall_score(trainlabels, clf.predict(traindata))\n",
    "print('Recall score: {0:0.2f}'.format(\n",
    "      recall))\n",
    "precision= precision_score(trainlabels, clf.predict(traindata))\n",
    "print('Precision score: {0:0.2f}'.format(\n",
    "      precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
