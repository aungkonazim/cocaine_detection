{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "23015e12-4784-4480-b3c7-b276fc8b0196"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "x = loadmat('theta.mat')\n",
    "theta_array = x['theta_array'][0]\n",
    "theta_label = x['theta_label'][0]\n",
    "X_digits = np.reshape(theta_array[0:1108],[1108,1])\n",
    "y_digits = theta_label\n",
    "\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "X_train = X_digits\n",
    "y_train = y_digits\n",
    "X_test = X_digits\n",
    "y_test = y_digits\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f' % logistic.fit(X_train, y_train).score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "837a0d1f-5b54-4de0-a75a-0a0718748f14"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "x = loadmat('theta.mat')\n",
    "theta_array = x['theta_array'][0]\n",
    "theta_label = x['theta_label'][0]\n",
    "X_digits = np.reshape(theta_array[0:1108],[1108,1])\n",
    "y_digits = theta_label\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "scores = cross_val_score(knn, X_digits, y_digits, cv=3)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "24ed2d9a-c388-4f8e-9c09-1ba122a37674"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "x = loadmat('theta1.mat')\n",
    "\n",
    "\n",
    "f1 = x['theta_array'][0]\n",
    "f2 = x['duration_array'][0]\n",
    "X_digits = [[f1[i],f2[i]] for i in range(len(f1))]\n",
    "y_digits = x['theta_label'][0]\n",
    "clf = svm.SVC('kernel': 'rbf', 'C': 0.000244140625, 'gamma': 0.000244140625, 'class_weight': {0: 0.5, 1: 0.5})\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "clf.fit(X_digits,y_digits)\n",
    "print(sum(y_digits))\n",
    "print(sum(clf.predict(X_digits)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5e74d662-3818-420d-9ac3-8197134331a0"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "439c1085-067c-40ab-885f-1188ac0e1a8f"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "x = loadmat('all_features.mat')\n",
    "f1 = x['theta_array'][0]\n",
    "f2 = x['duration_array'][0]\n",
    "f3 = x['PR80_array'][0]\n",
    "f4 = x['taur_array'][0]\n",
    "f5 = x['QD_array'][0]\n",
    "f6 = x['var_array'][0]\n",
    "f7 = x['activity_array'][0]\n",
    "f8 = x['PR20_array'][0]\n",
    "f9 = x['Power34_array'][0]\n",
    "f10 = x['Power23_array'][0]\n",
    "f11 = x['Power12_array'][0]\n",
    "f12 = x['f1_array'][0]\n",
    "f13 = x['f2_array'][0]\n",
    "f14 = x['mean_array'][0]\n",
    "f15 = x['median_array'][0]\n",
    "f16 = x['LFHF_array'][0]\n",
    "f17 = x['taud_array'][0]\n",
    "traindata = [[f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i],f17[i]]\n",
    "             for i in range(len(f1))]\n",
    "trainlabels = x['theta_label'][0]\n",
    "\n",
    "s = x['subject_array'][0]\n",
    "lkf = LabelKFold(s, n_folds=len(np.unique(s)))\n",
    "\n",
    "delta = 0.5\n",
    "parameters = {'kernel': ['rbf','linear'],\n",
    "              'C': [2 ** x for x in np.arange(-12, 12, 6)],\n",
    "              'gamma': [2 ** x for x in np.arange(-12, 12, 6)],\n",
    "              'class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.0, 1.0, delta)]}\n",
    "\n",
    "clf = svm.SVC(probability=True, verbose=False, cache_size=200)\n",
    "# clf = RandomForestClassifier(max_depth=None, n_estimators=35, max_features=len(traindata[0]))\n",
    "# clf = GridSearchCV(estimator=svc, param_grid=parameters,cv=lkf, n_jobs=20, scoring='f1_weighted', verbose=1, iid=False)\n",
    "clf.fit(traindata,trainlabels)\n",
    "# print(clf.best_params_)\n",
    "# print(sum(clf.predict(traindata)))\n",
    "print(sum(clf.predict(traindata)),sum(trainlabels))\n",
    "recall= recall_score(trainlabels, clf.predict(traindata))\n",
    "print('Recall score: {0:0.2f}'.format(\n",
    "      recall))\n",
    "precision= precision_score(trainlabels, clf.predict(traindata))\n",
    "print('Precision score: {0:0.2f}'.format(\n",
    "      precision))\n",
    "# print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ca42f1a6-e48d-4bd5-a167-d8f62adbd6c2"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression,RandomizedLasso,RandomizedLogisticRegression \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "x = loadmat('all_features.mat')\n",
    "f1 = x['theta_array'][0]\n",
    "f2 = x['duration_array'][0]\n",
    "f3 = x['PR80_array'][0]\n",
    "f4 = x['taur_array'][0]\n",
    "f5 = x['QD_array'][0]\n",
    "f6 = x['var_array'][0]\n",
    "f7 = x['activity_array'][0]\n",
    "f8 = x['PR20_array'][0]\n",
    "f9 = x['Power34_array'][0]\n",
    "f10 = x['Power23_array'][0]\n",
    "f11 = x['Power12_array'][0]\n",
    "f12 = x['f1_array'][0]\n",
    "f13 = x['f2_array'][0]\n",
    "f14 = x['mean_array'][0]\n",
    "f15 = x['median_array'][0]\n",
    "f16 = x['LFHF_array'][0]\n",
    "f17 = x['taud_array'][0]\n",
    "\n",
    "traindata = [[f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i]]\n",
    "             for i in range(len(f1))]\n",
    "trainlabels = x['theta_label'][0]\n",
    "\n",
    "f3 = x['subject_array'][0]\n",
    "lkf = LabelKFold(f3, n_folds=len(np.unique(f3)))\n",
    "# Recursive Feature Elimination\n",
    "# load the iris datasets\n",
    "# create a base classifier used to evaluate a subset of attributes\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(traindata, trainlabels)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(traindata, trainlabels)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)\n",
    "\n",
    "model = RandomizedLasso()\n",
    "model.fit(traindata, trainlabels)\n",
    "# display the relative importance of each attribute\n",
    "print(model.all_scores_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "11c79026-c58b-4432-9859-723381a40456"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    "from scipy.io import loadmat\n",
    "\n",
    "x = loadmat('all_features.mat')\n",
    "f1 = x['theta_array'][0]\n",
    "f2 = x['duration_array'][0]\n",
    "f3 = x['PR80_array'][0]\n",
    "f4 = x['taur_array'][0]\n",
    "f5 = x['QD_array'][0]\n",
    "f6 = x['var_array'][0]\n",
    "f7 = x['activity_array'][0]\n",
    "f8 = x['PR20_array'][0]\n",
    "f9 = x['Power34_array'][0]\n",
    "f10 = x['Power23_array'][0]\n",
    "f11 = x['Power12_array'][0]\n",
    "f12 = x['f1_array'][0]\n",
    "f13 = x['f2_array'][0]\n",
    "f14 = x['mean_array'][0]\n",
    "f15 = x['median_array'][0]\n",
    "f16 = x['LFHF_array'][0]\n",
    "f17 = x['taud_array'][0]\n",
    "\n",
    "traindata = [[f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i]]\n",
    "             for i in range(len(f1))]\n",
    "\n",
    "trainlabels = x['theta_label'][0]\n",
    "\n",
    "X = np.matrix(traindata)\n",
    "Y = trainlabels\n",
    "names = [\"x%s\" % i for i in range(1,15)]\n",
    " \n",
    "ranks = {}\n",
    " \n",
    "def rank_to_dict(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x, 2), ranks)\n",
    "    return dict(zip(names, ranks ))\n",
    " \n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(X, Y)\n",
    "ranks[\"Linear reg\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
    " \n",
    "ridge = Ridge(alpha=7)\n",
    "ridge.fit(X, Y)\n",
    "ranks[\"Ridge\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
    " \n",
    " \n",
    "lasso = Lasso(alpha=.05)\n",
    "lasso.fit(X, Y)\n",
    "ranks[\"Lasso\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
    " \n",
    " \n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "rlasso.fit(X, Y)\n",
    "ranks[\"Stability\"] = rank_to_dict(np.abs(rlasso.scores_), names)\n",
    " \n",
    "#stop the search when 5 features are left (they will get equal scores)\n",
    "# rfe = RFE(lr, n_features_to_select=5)\n",
    "# rfe.fit(X,Y)\n",
    "# ranks[\"RFE\"] = rank_to_dict(map(int, rfe.ranking_), names, order=-1)\n",
    " \n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X,Y)\n",
    "ranks[\"RF\"] = rank_to_dict(rf.feature_importances_, names)\n",
    " \n",
    " \n",
    "f, pval  = f_regression(X, Y, center=True)\n",
    "ranks[\"Corr.\"] = rank_to_dict(f, names)\n",
    " \n",
    "mine = MINE()\n",
    "mic_scores = []\n",
    "for i in range(X.shape[1]):\n",
    "    mine.compute_score(X[:][i], Y)\n",
    "    m = mine.mic()\n",
    "    mic_scores.append(m)\n",
    " \n",
    "ranks[\"MIC\"] = rank_to_dict(mic_scores, names) \n",
    " \n",
    " \n",
    "r = {}\n",
    "for name in names:\n",
    "    r[name] = round(np.mean([ranks[method][name] \n",
    "                             for method in ranks.keys()]), 2)\n",
    " \n",
    "methods = sorted(ranks.keys())\n",
    "ranks[\"Mean\"] = r\n",
    "methods.append(\"Mean\")\n",
    " \n",
    "print (\"\\t%s\" % \"\\t\".join(methods))\n",
    "for name in names:\n",
    "    print (\"%s\\t%s\" % (name, \"\\t\".join(map(str, \n",
    "                         [ranks[method][name] for method in methods]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "f9648b0f-1d16-4045-b453-243279f1f1d1"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def normalize(v):\n",
    "    norm=np.linalg.norm(v)\n",
    "    if norm==0: \n",
    "       return v\n",
    "    return v/norm\n",
    "\n",
    "\n",
    "x = loadmat('all_features_baseline_corrected_monowar_model_outlier_included.mat')\n",
    "f1 = normalize(x['theta_array'][0])\n",
    "f2 = normalize(x['duration_array'][0])\n",
    "f3 = normalize(x['PR80_array'][0])\n",
    "f4 = normalize(x['taur_array'][0])\n",
    "f5 = normalize(x['QD_array'][0])\n",
    "f6 = normalize(x['var_array'][0])\n",
    "f7 = normalize(x['activity_array'][0])\n",
    "f8 = normalize(x['PR20_array'][0])\n",
    "f9 = normalize(x['Power34_array'][0])\n",
    "f10 = normalize(x['Power23_array'][0])\n",
    "f11 = normalize(x['Power12_array'][0])\n",
    "f12 = normalize(x['f1_array'][0])\n",
    "f13 = normalize(x['f2_array'][0])\n",
    "f14 = normalize(x['mean_array'][0])\n",
    "f15 = normalize(x['median_array'][0])\n",
    "f16 = normalize(x['LFHF_array'][0])\n",
    "f17 = normalize(x['taud_array'][0])\n",
    "f18 = normalize(x['range_array'][0]\n",
    "traindata = [f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i],f17[i],f18[i] for i in range(len(f1))]\n",
    "trainlabels = x['theta_label'][0]\n",
    "\n",
    "# s = x['subject_array'][0]\n",
    "# # lkf = LabelKFold(s, n_folds=len(np.unique(s)))\n",
    "\n",
    "# # delta = 0.5\n",
    "# # parameters = {'kernel': ['rbf','linear'],\n",
    "# #               'C': [2 ** x for x in np.arange(-12, 12, 6)],\n",
    "# #               'gamma': [2 ** x for x in np.arange(-12, 12, 6)],\n",
    "# #               'class_weight': [{0: w, 1: 1 - w} for w in np.arange(0.0, 1.0, delta)]}\n",
    "\n",
    "# # clf = svm.SVC(probability=True, verbose=False, cache_size=200)\n",
    "\n",
    "# X = np.array(traindata)\n",
    "# y = np.array(trainlabels)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=3)\n",
    "# skf.get_n_splits(X, y)\n",
    "# for train_index, test_index in skf.split(X, y):\n",
    "#     train_index = np.int64(np.array(train_index))\n",
    "#     test_index = np.int64(np.array(test_index))\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "#     clf = RandomForestClassifier(max_depth=None, n_estimators=50, max_features=len(traindata[0]))\n",
    "#     # clf = GridSearchCV(estimator=svc, param_grid=parameters,cv=lkf, n_jobs=20, scoring='f1_weighted', verbose=1, iid=False)\n",
    "    \n",
    "#     clf.fit(X_train,y_train)\n",
    "#     # print(clf.best_params_)\n",
    "#     # print(sum(clf.predict(traindata)))\n",
    "    \n",
    "#     recall= recall_score(y_test, clf.predict(X_test))\n",
    "#     print('Recall score: {0:0.2f}'.format(\n",
    "#           recall),sum(y_test),sum(clf.predict(X_test)))\n",
    "#     precision= precision_score(y_test, clf.predict(X_test))\n",
    "#     print('Precision score: {0:0.2f}'.format(\n",
    "#           precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "import itertools\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import tree\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def normalize(v):\n",
    "    norm=np.linalg.norm(v)\n",
    "    if norm==0:\n",
    "        return v\n",
    "    return v/norm\n",
    "\n",
    "\n",
    "x = loadmat('all_features_baseline_corrected_monowar_model_outlier_diff_included.mat')\n",
    "f1 = normalize(x['theta_array'][0])\n",
    "f2 = normalize(x['duration_array'][0])\n",
    "f3 = normalize(x['PR80_array'][0])\n",
    "f4 = normalize(x['taur_array'][0])\n",
    "f5 = normalize(x['QD_array'][0])\n",
    "f6 = normalize(x['var_array'][0])\n",
    "f7 = normalize(x['activity_array'][0])\n",
    "f8 = normalize(x['PR20_array'][0])\n",
    "f9 = normalize(x['Power34_array'][0])\n",
    "f10 = normalize(x['Power23_array'][0])\n",
    "f11 = normalize(x['Power12_array'][0])\n",
    "f12 = normalize(x['f1_array'][0])\n",
    "f13 = normalize(x['f2_array'][0])\n",
    "f14 = normalize(x['mean_array'][0])\n",
    "f15 = normalize(x['median_array'][0])\n",
    "f16 = normalize(x['LFHF_array'][0])\n",
    "f17 = normalize(x['taud_array'][0])\n",
    "f18 = normalize(x['range_array'][0])\n",
    "f19 = normalize(x['diff_median_array'][0])\n",
    "\n",
    "traindata= [[f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i],f17[i],f18[i],f19[i]]\n",
    "            for i in range(len(f1))]\n",
    "\n",
    "# traindata= [[f1[i],f2[i],f4[i],f17[i]] for i in range(len(f1))]\n",
    "\n",
    "trainlabels = x['theta_label'][0]\n",
    "\n",
    "s = x['subject_array'][0]\n",
    "\n",
    "x = list(traindata)\n",
    "y = list(trainlabels)\n",
    "\n",
    "for i,element in enumerate(trainlabels):\n",
    "    if element == 1:\n",
    "        x.append(traindata[i])\n",
    "        y.append(element)\n",
    "\n",
    "trainlabels = np.array(y)\n",
    "traindata = np.array(x)\n",
    "\n",
    "\n",
    "# sm = SMOTEENN()\n",
    "# traindata, trainlabels = sm.fit_sample(traindata, trainlabels)\n",
    "print(len(trainlabels))\n",
    "ss = ShuffleSplit(n_splits=4, test_size=0.25,random_state=10)\n",
    "precision_score1 = []\n",
    "recall_score1 = []\n",
    "kappa_score1 = []\n",
    "accuracy_score1 = []\n",
    "\n",
    "for train_index, test_index in ss.split(trainlabels):\n",
    "    x_train,y_train = traindata[train_index],trainlabels[train_index]\n",
    "    x_test,y_test = traindata[test_index],trainlabels[test_index]\n",
    "    class_weight1 ={}\n",
    "    class_weight1[0] = 30\n",
    "    class_weight1[1] = 500\n",
    "    clf = RandomForestClassifier(max_depth=None, n_estimators=35, max_features=len(traindata[0]),class_weight=class_weight1)\n",
    "#     clf = svm.SVC()\n",
    "#     clf = DecisionTreeClassifier()\n",
    "    clf.fit(x_train,y_train)\n",
    "    recall= recall_score(y_test, clf.predict(x_test))\n",
    "    recall_score1.append(recall)\n",
    "    print('Recall score: {0:0.2f}'.format(recall))\n",
    "    precision= precision_score(y_test, clf.predict(x_test))\n",
    "    precision_score1.append(precision)\n",
    "    print('Precision score: {0:0.2f}'.format(precision))\n",
    "    f1 = accuracy_score(y_test, clf.predict(x_test))\n",
    "    accuracy_score1.append(f1)\n",
    "    print('accuracy score: {0:0.2f}'.format(f1))\n",
    "    kappa = cohen_kappa_score(y_test, clf.predict(x_test))\n",
    "    kappa_score1.append(kappa)\n",
    "    print('cohen kappa score: {0:0.2f}'.format(kappa))\n",
    "    cnf_matrix = confusion_matrix(y_test, clf.predict(x_test))\n",
    "    print(\"confusion matrix\\n\",cnf_matrix)\n",
    "#     print(\"Results\\n\",classification_report_imbalanced(y_test, pipeline.predict(x_test)))\n",
    "    y_score = clf.predict(x_test)\n",
    "    average_precision = average_precision_score(y_test, y_score)\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "    plt.figure()\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AUC={0:0.2f}'.format(average_precision))\n",
    "    plt.show()\n",
    "    print(clf.feature_importances_)\n",
    "   \n",
    "\n",
    "print(\"Average Recall\",np.mean(recall_score1))  \n",
    "print(\"Average Precision\",np.mean(precision_score1))\n",
    "print(\"Average Accuracy\",np.mean(accuracy_score1))\n",
    "print(\"Average Cohen-Kappa\",np.mean(kappa_score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import itertools\n",
    "from sklearn import svm, grid_search, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn import svm, metrics, preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn import tree\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def normalize(v):\n",
    "    norm=np.linalg.norm(v)\n",
    "    if norm==0:\n",
    "        return v\n",
    "    return v/norm\n",
    "\n",
    "\n",
    "x = loadmat('all_features_baseline_corrected_monowar_model_outlier_diff_included.mat')\n",
    "f1 = normalize(x['theta_array'][0])\n",
    "f2 = normalize(x['duration_array'][0])\n",
    "f3 = normalize(x['PR80_array'][0])\n",
    "f4 = normalize(x['taur_array'][0])\n",
    "f5 = normalize(x['QD_array'][0])\n",
    "f6 = normalize(x['var_array'][0])\n",
    "f7 = normalize(x['activity_array'][0])\n",
    "f8 = normalize(x['PR20_array'][0])\n",
    "f9 = normalize(x['Power34_array'][0])\n",
    "f10 = normalize(x['Power23_array'][0])\n",
    "f11 = normalize(x['Power12_array'][0])\n",
    "f12 = normalize(x['f1_array'][0])\n",
    "f13 = normalize(x['f2_array'][0])\n",
    "f14 = normalize(x['mean_array'][0])\n",
    "f15 = normalize(x['median_array'][0])\n",
    "f16 = normalize(x['LFHF_array'][0])\n",
    "f17 = normalize(x['taud_array'][0])\n",
    "f18 = normalize(x['range_array'][0])\n",
    "f19 = normalize(x['diff_median_array'][0])\n",
    "\n",
    "traindata= [[f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i],f17[i],f18[i],f19[i]]\n",
    "            for i in range(len(f1))]\n",
    "\n",
    "# traindata= [[f1[i],f2[i],f4[i],f17[i]] for i in range(len(f1))]\n",
    "\n",
    "trainlabels = x['theta_label'][0]\n",
    "\n",
    "s = x['subject_array'][0]\n",
    "\n",
    "\n",
    "x = list(traindata)\n",
    "y = list(trainlabels)\n",
    "\n",
    "for i,element in enumerate(trainlabels):\n",
    "    if element == 1:\n",
    "        x.append(traindata[i])\n",
    "        y.append(element)\n",
    "\n",
    "trainlabels = np.array(y)\n",
    "traindata = np.array(x)\n",
    "\n",
    "x = loadmat('C:\\\\Users\\\\aungkon\\\\Desktop\\\\jhu\\\\code\\\\code_final\\\\NIDA\\\\all_features_in_NIDA.mat')\n",
    "f1 = normalize(x['theta_array'][0])\n",
    "f2 = normalize(x['duration_array'][0])\n",
    "f3 = normalize(x['PR80_array'][0])\n",
    "f4 = normalize(x['taur_array'][0])\n",
    "f5 = normalize(x['QD_array'][0])\n",
    "f6 = normalize(x['var_array'][0])\n",
    "f7 = normalize(x['activity_array'][0])\n",
    "f8 = normalize(x['PR20_array'][0])\n",
    "f9 = normalize(x['Power34_array'][0])\n",
    "f10 = normalize(x['Power23_array'][0])\n",
    "f11 = normalize(x['Power12_array'][0])\n",
    "f12 = normalize(x['f1_array'][0])\n",
    "f13 = normalize(x['f2_array'][0])\n",
    "f14 = normalize(x['mean_array'][0])\n",
    "f15 = normalize(x['median_array'][0])\n",
    "f16 = normalize(x['LFHF_array'][0])\n",
    "f17 = normalize(x['taud_array'][0])\n",
    "f18 = normalize(x['range_array'][0])\n",
    "f19 = normalize(x['diff_median_array'][0])\n",
    "\n",
    "testdata= [[f1[i],f2[i],f3[i],f4[i],f5[i],f6[i],f7[i],f8[i],f9[i],f10[i],f11[i],f12[i],f13[i],f14[i],f15[i],f16[i],f17[i],f18[i],f19[i]]\n",
    "            for i in range(len(f1))]\n",
    "\n",
    "# traindata= [[f1[i],f2[i],f4[i],f17[i]] for i in range(len(f1))]\n",
    "\n",
    "testlabels = x['theta_label'][0]\n",
    "\n",
    "s = x['subject_array'][0]\n",
    "\n",
    "# sm = SMOTEENN()\n",
    "traindata, trainlabels = sm.fit_sample(traindata, trainlabels)\n",
    "\n",
    "# testdata, testlabels = sm.fit_sample(testdata, testlabels)\n",
    "print(len(testlabels[testlabels==0]))\n",
    "print(len(testlabels[testlabels==1]))\n",
    "\n",
    "x_train = np.array(traindata)\n",
    "x_test = np.array(testdata)\n",
    "y_train = np.array(trainlabels)\n",
    "y_test = np.array(testlabels)\n",
    "\n",
    "\n",
    "# class_weight1 ={}\n",
    "# class_weight1[0] = 30\n",
    "# class_weight1[1] = 30\n",
    "# clf = RandomForestClassifier(max_depth=100, n_estimators=350, max_features=len(traindata[0]))\n",
    "clf = DecisionTreeClassifier()\n",
    "# clf = svm.SVC()\n",
    "clf.fit(x_train,y_train)\n",
    "recall= recall_score(y_test, clf.predict(x_test))\n",
    "print('Recall score: {0:0.2f}'.format(recall))\n",
    "precision= precision_score(y_test, clf.predict(x_test))\n",
    "print('Precision score: {0:0.2f}'.format(precision))\n",
    "f1 = accuracy_score(y_test, clf.predict(x_test))\n",
    "print('accuracy score: {0:0.2f}'.format(f1))\n",
    "kappa = cohen_kappa_score(y_test, clf.predict(x_test))\n",
    "print('cohen kappa score: {0:0.2f}'.format(kappa))\n",
    "cnf_matrix = confusion_matrix(y_test, clf.predict(x_test))\n",
    "print(\"confusion matrix\\n\",cnf_matrix)\n",
    "#     print(\"Results\\n\",classification_report_imbalanced(y_test, pipeline.predict(x_test)))\n",
    "y_score = clf.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "plt.figure()\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('2-class Precision-Recall curve: AUC={0:0.2f}'.format(average_precision))\n",
    "plt.show()\n",
    "# print(clf.feature_importances_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
